{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from ultralytics import YOLO  #object detection algorithm\n",
    "import cv2  #videos\n",
    "import pandas as pd #csv\n",
    "import os #to get files automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get participant and recording number\n",
    "participant_number = input(\"Enter participant number: \")\n",
    "recording_number = input(\"Enter recording number: \") \n",
    "\n",
    "base_path = \"/net/store/nbp/projects/OsnaPlaza/Body/raw/unprocessed videos\"\n",
    "saving_file_path = \"/net/store/nbp/projects/OsnaPlaza/Body/raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating video and making a dataframe with detections ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# input video\n",
    "video_path = os.path.join(base_path, f\"{participant_number}_{recording_number}.mp4\")\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# input video information\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total number of frames\n",
    "fr = cap.get(cv2.CAP_PROP_FPS)  # Frame rate (frames per second)\n",
    "video_duration = frame_count / fr  # Duration in seconds\n",
    "\n",
    "print(f\"Total frames: {frame_count}\")\n",
    "print(f\"Frame rate: {fr} FPS\")\n",
    "print(f\"Video duration: {video_duration:.2f} seconds\")\n",
    "\n",
    "# for output video (annotated video)\n",
    "output_path = os.path.join(base_path, f\"yolo_{participant_number}_{recording_number}.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_path, fourcc, fr, (int(cap.get(3)), int(cap.get(4)))) #making sure the output video has same attributes as the input \n",
    "\n",
    "# comment out previous line if don't want the video output to be saved\n",
    "\n",
    "## for a detections df\n",
    "detections = [] # a list to for detection results\n",
    "frame_count = 0 # initialising frame count\n",
    "\n",
    "while cap.isOpened(): # a loop getting frames until the video is finished\n",
    "    ret, frame = cap.read() \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1  # Track the frame number\n",
    "\n",
    "    # Run YOLOv8 detection on the current frame\n",
    "    results = model(frame,classes=0) # results = model(frame,classes=0) - for only person detection\n",
    "\n",
    "    # Save detections to the list\n",
    "    for result in results[0].boxes.data:\n",
    "        x_min, y_min, x_max, y_max, confidence, class_id = result\n",
    "        class_label = model.names[int(class_id)]  # get class name from class ID\n",
    "        detections.append([frame_count, x_min.item(), y_min.item(), x_max.item(), y_max.item(), confidence.item(), class_label])\n",
    "\n",
    "    # Annotate frame with bounding boxes and save to output video\n",
    "    annotated_frame = results[0].plot()\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    ##  to display the annotated frame during the process\n",
    "    '''cv2.imshow(\"YOLO Detection\", annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break'''\n",
    "\n",
    "# making a df\n",
    "columns = [\"Frame\", \"X_min\", \"Y_min\", \"X_max\", \"Y_max\", \"Confidence\", \"Class\"]\n",
    "detections_df = pd.DataFrame(detections, columns=columns)\n",
    "saving_path = os.path.join(saving_file_path, f\"detections_{participant_number}_{recording_number}.csv\")\n",
    "detections_df.to_csv(saving_path, index=False)\n",
    "\n",
    "cap.release() # closes the video file\n",
    "out.release() # closes the video writer\n",
    "cv2.destroyAllWindows() # closes any OpenCV windows\n",
    "\n",
    "display(detections_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
